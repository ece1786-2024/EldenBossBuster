{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG_agent:\n",
    "    def __init__(self, index_path):\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "        index = load_index_from_storage(storage_context)\n",
    "        llm = OpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0.2,\n",
    "            num_outputs=1000,\n",
    "        )\n",
    "        self.query_engine = index.as_query_engine(response_mode=\"refine\", similarity_top_k=5, verbose = True, llm = llm)\n",
    "\n",
    "    def query(self, query):\n",
    "        return self.query_engine.query(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query_agent:\n",
    "    # This agent takes user prompt and refine to a query for specific RAG agent\n",
    "    def __init__(self, description, history):\n",
    "        self.client = openai.OpenAI()\n",
    "        self.history = history\n",
    "        self.description = [\n",
    "            {\"role\": \"system\", \"content\": description},\n",
    "        ]\n",
    "\n",
    "    def create_query(self):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=self.history + self.description,\n",
    "            max_tokens=1000,\n",
    "            n=1,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0.2,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response_agent:\n",
    "    # This agent takes the history and create the final response to user\n",
    "    def __init__(self, description, history):\n",
    "        self.client = openai.OpenAI()\n",
    "        self.messages = history\n",
    "        self.description = [\n",
    "            {\"role\": \"system\", \"content\": description},\n",
    "        ]\n",
    "\n",
    "    def respond(self):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=self.messages + self.description,\n",
    "            max_tokens=1000,\n",
    "            n=1,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0.2,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompt(filename):\n",
    "    with open(f'agent_descriptions/{filename}.txt', 'r') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "STRATEGY_QUERY_DESCRIPTION = load_prompt('strategy_agent')\n",
    "GAMEINFO_QUERY_DESCRIPTION = load_prompt('gameinfo_agent')\n",
    "FINAL_RESPONSE_DESCRIPTION = load_prompt('final_agent')\n",
    "LOOP_RESPONSE_DESCRIPTION = load_prompt('loop_agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORD = \"ADDITIONAL_QUERY_REQUIRED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EldenGuideSystem:\n",
    "    # The agent system that takes user prompt and return the final response\n",
    "    def __init__(self, strategy_agent, gameinfo_agent, \n",
    "                 strategy_query_description, \n",
    "                 gameinfo_query_description, \n",
    "                 loop_response_description, \n",
    "                 final_response_description):\n",
    "        self.messages = []\n",
    "        self.strategy_agent = strategy_agent\n",
    "        self.gameinfo_agent = gameinfo_agent\n",
    "        self.strategy_query_agent = Query_agent(strategy_query_description, self.messages)\n",
    "        self.gameinfo_query_agent = Query_agent(gameinfo_query_description, self.messages)\n",
    "        self.loop_response_agent = Response_agent(loop_response_description, self.messages)\n",
    "        self.final_response_agent = Response_agent(final_response_description, self.messages)\n",
    "\n",
    "    def push_assistant_message(self, message):\n",
    "        self.messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message\n",
    "        })\n",
    "\n",
    "    def run(self, prompt):\n",
    "        count = 0\n",
    "        self.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        while count < 3:\n",
    "            print(f\"Querying... {count}\")\n",
    "            strategy_query = self.strategy_query_agent.create_query()\n",
    "            strategy_response = self.strategy_agent.query(strategy_query)\n",
    "            self.push_assistant_message(\"Strategy query result: \" + str(strategy_response))\n",
    "            gameinfo_query = self.gameinfo_query_agent.create_query()\n",
    "            gameinfo_response = self.gameinfo_agent.query(gameinfo_query)\n",
    "            self.push_assistant_message(\"In-game data query result: \" + str(gameinfo_response))\n",
    "            loop_response = self.loop_response_agent.respond()\n",
    "            if KEYWORD in loop_response:\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if count >= 3:\n",
    "            final_response = self.final_response_agent.respond()\n",
    "        else:\n",
    "            final_response = loop_response\n",
    "        return final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index paths\n",
    "strategy_path = \"index/strategy\"\n",
    "gameinfo_path = \"index/game\"\n",
    "altogether_path = \"index/altogether\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_agent = RAG_agent(strategy_path)\n",
    "gameinfo_agent = RAG_agent(gameinfo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Nagakiba belongs to which NPC?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying... 0\n",
      "In Elden Ring, the Nagakiba is associated with the NPC Yura, Hunter of Bloody Fingers. You can obtain the Nagakiba by progressing through Yura's questline, which involves assisting him in fighting against Bloody Finger invaders. Alternatively, if Yura is defeated at any point, the Nagakiba can be collected from his location.\n"
     ]
    }
   ],
   "source": [
    "system = EldenGuideSystem(strategy_agent, gameinfo_agent,\n",
    "                          STRATEGY_QUERY_DESCRIPTION,\n",
    "                          GAMEINFO_QUERY_DESCRIPTION,\n",
    "                          LOOP_RESPONSE_DESCRIPTION,\n",
    "                          FINAL_RESPONSE_DESCRIPTION)\n",
    "response = system.run(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'Nagakiba belongs to which NPC?'}\n",
      "{'role': 'assistant', 'content': 'Strategy query result: To create an effective weapon strategy build for the Nagakiba in Elden Ring, utilize its long reach and versatility by boosting Dexterity and Strength to maximize damage. Infuse the weapon with Ashes of War that align with your combat style, whether aggressive or tactical. Enhance the build further by using talismans or armor that increase Dexterity or overall attack power.'}\n",
      "{'role': 'assistant', 'content': \"In-game data query result: I'm sorry, the information regarding the location of the Nagakiba weapon is not available.\"}\n"
     ]
    }
   ],
   "source": [
    "for message in system.messages:\n",
    "    print(message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elden",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
